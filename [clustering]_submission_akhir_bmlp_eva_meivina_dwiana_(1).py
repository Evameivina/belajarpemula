# -*- coding: utf-8 -*-
"""[Clustering]_Submission_Akhir_BMLP_EVA_MEIVINA_DWIANA (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nby3DwbqboZEvLzXeD62PZUMHoxUrCkB

# **Penting**
- Jangan mengubah atau menambahkan cell text yang sudah disediakan, Anda hanya perlu mengerjakan cell code yang sudah disediakan.
- Pastikan seluruh kriteria memiliki output yang sesuai, karena jika tidak ada output dianggap tidak selesai.
- Misal, Anda menggunakan df = df.dropna() silakan gunakan df.isnull().sum() sebagai tanda sudah berhasil. Silakan sesuaikan seluruh output dengan perintah yang sudah disediakan.
- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.
- Pastikan Anda menggunakan variabel df dari awal sampai akhir dan tidak diperbolehkan mengganti nama variabel tersebut.
- Hapus simbol pagar (#) pada kode yang bertipe komentar jika Anda menerapkan kriteria tambahan
- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan
- Pastikan Anda mengerjakan sesuai section yang sudah diberikan tanpa mengubah judul atau header yang disediakan.

# **INFORMASI DATASET**

Dataset ini menyajikan gambaran mendalam mengenai perilaku transaksi dan pola aktivitas keuangan, sehingga sangat ideal untuk eksplorasi **deteksi penipuan (fraud detection)** dan **identifikasi anomali**. Dataset ini mencakup **2.512 sampel data transaksi**, yang mencakup berbagai atribut transaksi, demografi nasabah, dan pola penggunaan.

Setiap entri memberikan wawasan komprehensif terhadap perilaku transaksi, memungkinkan analisis untuk **keamanan finansial** dan pengembangan model prediktif.

## Fitur Utama

- **`TransactionID`**: Pengidentifikasi unik alfanumerik untuk setiap transaksi.  
- **`AccountID`**: ID unik untuk setiap akun, dapat memiliki banyak transaksi.  
- **`TransactionAmount`**: Nilai transaksi dalam mata uang, mulai dari pengeluaran kecil hingga pembelian besar.  
- **`TransactionDate`**: Tanggal dan waktu transaksi terjadi.  
- **`TransactionType`**: Tipe transaksi berupa `'Credit'` atau `'Debit'`.  
- **`Location`**: Lokasi geografis transaksi (nama kota di Amerika Serikat).  
- **`DeviceID`**: ID perangkat yang digunakan dalam transaksi.  
- **`IP Address`**: Alamat IPv4 yang digunakan saat transaksi, dapat berubah untuk beberapa akun.  
- **`MerchantID`**: ID unik merchant, menunjukkan merchant utama dan anomali transaksi.  
- **`AccountBalance`**: Saldo akun setelah transaksi berlangsung.  
- **`PreviousTransactionDate`**: Tanggal transaksi terakhir pada akun, berguna untuk menghitung frekuensi transaksi.  
- **`Channel`**: Kanal transaksi seperti `Online`, `ATM`, atau `Branch`.  
- **`CustomerAge`**: Usia pemilik akun.  
- **`CustomerOccupation`**: Profesi pengguna seperti `Dokter`, `Insinyur`, `Mahasiswa`, atau `Pensiunan`.  
- **`TransactionDuration`**: Lama waktu transaksi (dalam detik).  
- **`LoginAttempts`**: Jumlah upaya login sebelum transaksiâ€”jumlah tinggi bisa mengindikasikan anomali.

Tugas kamu adalah membuat model clustering yang selanjutnya akan digunakan untuk membuat model klasifikasi.

# **1. Import Library**
Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning. Semua library yang dibutuhkan harus **import** di **cell** ini, jika ada library yang dijalankan di cell lain maka **submission langsung ditolak**
"""

#Type your code here
import joblib
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from yellowbrick.cluster import KElbowVisualizer
from sklearn.preprocessing import MinMaxScaler, LabelEncoder

"""# **2. Memuat Dataset**
Pada tahap ini, Anda perlu memuat dataset ke dalam notebook lalu mengecek informasi dataset sebelum nantinya dilakukan pembersihan. Hal-hal yang perlu dilakukan pada tahapan ini yaitu:
1. **Memahami Struktur Data**
   - Dataset harus mengambil referensi wajib digunakan (bisa dilihat [Disini](https://drive.google.com/drive/folders/1Zs7VmPZ-jNwsRlMKH65Ea-LApSwx6lKx?usp=drive_link))
   - Melakukan loading dataset ke dalam notebook dan menampilkan 5 baris pertama dengan function `head`.
   - Tinjau jumlah baris kolom dan jenis data dalam dataset dengan function `info`.  
   - Menampilkan statistik deskriptif dataset dengan menjalankan `describe`.
   - Pastikan **setiap function tersebut** memiliki **output pada setiap cell** code. Jika tidak **submission langsung ditolak**

Gunakan code ini untuk melakukan load data secara otomatis tanpa harus download data tersebut secara manual:
```python
url='https://drive.google.com/uc?id=1gnLO9qvEPqv1uBt1928AcsCmdvzqjC5m'
df = pd.read_csv(url)
```

Penting: pada kriteria pertama hindari penggunaan print() dan display() karena seluruh fungsi yang digunakan sudah memiliki standar output dan menghasilkan output yang diharapkan.

Kriteria 1 akan ditolak ketika:
- print(__.head())
- display(___.head())
dst

Kriteria 1 akan diterima ketika Anda menggunakan fungsi yang diminta tanpa menambahkan deskripsi apapun.
"""

# Load data
url = 'https://drive.google.com/uc?id=1gnLO9qvEPqv1uBt1928AcsCmdvzqjC5m'
df = pd.read_csv(url)

# Tampilkan 5 baris pertama dengan function head.
df.head()

# Tinjau jumlah baris kolom dan jenis data dalam dataset dengan info.
df.info()

# Menampilkan statistik deskriptif dataset dengan menjalankan describe
df.describe()

"""(Opsional) Memuat Dataset dan Melakukan Exploratory Data Analysis (EDA) [Skilled]

**Biarkan kosong jika tidak menerapkan kriteria skilled**

**Apabila ingin menerapkan Advanced, pastikan seluruh visualisasi tidak ada yang overlap**
"""

# Menampilkan korelasi antar fitur (Opsional Skilled 1)

numeric_cols = df.select_dtypes(include=np.number).columns
sns.heatmap(df[numeric_cols].corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

# Menampilkan histogram untuk semua kolom numerik (Opsional Skilled 1)

df.hist(figsize=(15,10), bins=20, color='skyblue')
plt.tight_layout()
plt.show()

"""(Opsional) Memuat Dataset dan Melakukan Exploratory Data Analysis (EDA) [Advanced]

**Biarkan kosong jika tidak menerapkan kriteria advanced**
"""

# Visualisasi yang lebih informatif (Opsional Advanced 1)
plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='AccountBalance', y='TransactionAmount', hue='TransactionType', alpha=0.7)
plt.title("Transaction Amount vs Account Balance")
plt.xlabel("Account Balance ($)")
plt.ylabel("Transaction Amount ($)")
plt.show()

"""# **3. Pembersihan dan Pra Pemrosesan Data**

Pada tahap ini, Anda akan melakukan **Pembersihan Dataset** untuk menjadikan dataset mudah diintepretasi dan bisa dilatih. Hal-hal yang wajib kamu lakukan yaitu:

1. **Mengecek dataset** menggunakan isnull().sum() dan duplicated().sum().
2. Melakukan feature scaling menggunakan `MinMaxScaler()` atau `StandardScalar()` untuk fitur numerik.
3. Melakukan feature encoding menggunakan `LabelEncoder()` untuk fitur kategorikal.
4. Melakukan drop pada kolom id.
5. **Ketentuan Cell Code**
   - Pastikan **setiap pemeriksaan tersebut** memiliki **output pada cell-nya**. Jika tidak **submission langsung ditolak**

"""

# Mengecek dataset menggunakan isnull().sum()
df.isnull().sum()

# Mengecek dataset menggunakan duplicated().sum()
df.duplicated().sum()

# Melakukan feature scaling menggunakan MinMaxScaler() atau StandardScalar() untuk fitur numerik.
# Pastikan kamu menggunakan function head setelah melalukan scaling.
numeric_cols = ['TransactionAmount', 'AccountBalance', 'TransactionDuration', 'LoginAttempts', 'CustomerAge']
scaler = MinMaxScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# Melakukan drop pada kolom yang memiliki keterangan id dan IP Address
df = df.drop(columns=['TransactionID', 'AccountID', 'DeviceID', 'IP Address', 'MerchantID'])

# Melakukan feature encoding menggunakan LabelEncoder() untuk fitur kategorikal.
# Pastikan kamu menggunakan function head setelah melalukan encoding.
categorical_cols = ['TransactionType', 'Location', 'Channel', 'CustomerOccupation']
encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str)) # Convert to string to handle potential NaN values
    encoders[col] = le

df.head()

# Last checking gunakan columns.tolist() untuk checking seluruh fitur yang ada.
# Perbaiki kode di bawah ini tanpa menambahkan atau mengurangi cell code ini.
# ____.columns.tolist()
df.columns.tolist()

"""(Opsional) Pembersihan dan Pra Pemrosesan Data [Skilled]

**Biarkan kosong jika tidak menerapkan kriteria skilled**
"""

# Menangani data yang hilang (bisa menggunakan dropna() atau metode imputasi fillna()).
numeric_cols = df.select_dtypes(include=np.number).columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())

# Menghapus data duplikat menggunakan drop_duplicates().
df = df.drop_duplicates()

"""(Opsional) Pembersihan dan Pra Pemrosesan Data [Advanced]

**Biarkan kosong jika tidak menerapkan kriteria advanced**
"""

# Melakukan Handling Outlier Data berdasarkan jumlah outlier dengan metode clipping menggunakan .loc
Q1 = df['TransactionAmount'].quantile(0.25)
Q3 = df['TransactionAmount'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5*IQR
upper_bound = Q3 + 1.5*IQR

df.loc[:, 'TransactionAmount'] = np.where(
    df['TransactionAmount'] < lower_bound, lower_bound,
    np.where(df['TransactionAmount'] > upper_bound, upper_bound, df['TransactionAmount'])
)

# Melakukan binning data berdasarkan kondisi rentang nilai pada fitur numerik,
# lakukan pada satu sampai dua fitur numerik.
# Silahkan lakukan encode hasil binning tersebut menggunakan LabelEncoder.
# Pastikan kamu mengerjakan tahapan ini pada satu cell.

age_bins = [0, 30, 50, 100]
age_labels = ['Young', 'Middle', 'Senior']
df['AgeGroup'] = pd.cut(df['CustomerAge'], bins=age_bins, labels=age_labels)

# Use quantiles to define bins for TransactionDuration
bins_duration = df['TransactionDuration'].quantile([0, 0.33, 0.66, 1]).tolist()
labels_duration = ['Short', 'Medium', 'Long']
df['DurationGroup'] = pd.cut(df['TransactionDuration'], bins=bins_duration, labels=labels_duration, include_lowest=True)

le = LabelEncoder()
df['AgeGroup'] = le.fit_transform(df['AgeGroup'].astype(str))
df['DurationGroup'] = le.fit_transform(df['DurationGroup'].astype(str))

df[['CustomerAge', 'TransactionDuration', 'AgeGroup', 'DurationGroup']].head()

"""# **4. Membangun Model Clustering**
Pada tahap ini, Anda membangun model clustering dengan memilih algoritma yang sesuai untuk mengelompokkan data berdasarkan kesamaan.
1. Pastikan Anda menggunakan dataframe yang sudah melalui processing sesuai dengan levelnya (Basic, Skilled, Advanced)
2. Melakukan visualisasi Elbow Method untuk menentukan jumlah cluster terbaik menggunakan `KElbowVisualizer()`.
3. Menggunakan algoritma K-Means Clustering dengan `sklearn.cluster.KMeans()`.
4. Jalankan cell code `joblib.dump(model_kmeans, "model_clustering.h5")` untuk menyimpan model yang sudah dibuat.
"""

# Gunakan describe untuk memastikan proses clustering menggunakan dataset hasil preprocessing
# Lengkapi kode ini dengan mengubah nama DataFrame yang akan dilatih.
# Kode harus digunakan dan dilarang menambahkan syntax lainnya pada cell ini.
# ___.describe()

df.describe()

features = ['TransactionAmount', 'AccountBalance', 'TransactionDuration', 'LoginAttempts', 'CustomerAge', 'AgeGroup', 'DurationGroup']

# Melakukan visualisasi Elbow Method menggunakan KElbowVisualizer()
model = KMeans()
visualizer = KElbowVisualizer(model, k=(2,10))
visualizer.fit(df[features])
visualizer.show()

# Menggunakan algoritma K-Means Clustering
model_kmeans = KMeans(n_clusters=3, random_state=42)
model_kmeans.fit(df[features])

"""Jalankan cell code ini untuk menyimpan model kamu."""

# Menyimpan model menggunakan joblib
# import joblib
# joblib.dump(___, "model_clustering.h5")
joblib.dump(model_kmeans, "model_clustering.h5")

"""(Opsional) Membangun Model Clustering [Skilled]

**Biarkan kosong jika tidak menerapkan kriteria skilled**
"""

# Menghitung dan menampilkan nilai Silhouette Score.
labels = model_kmeans.labels_
sil_score = silhouette_score(df[features], labels)
sil_score

# Membuat visualisasi hasil clustering
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
components = pca.fit_transform(df[features])

plt.figure(figsize=(8,6))
plt.scatter(components[:,0], components[:,1], c=labels, cmap='viridis', s=50)
plt.title('Visualisasi Hasil Clustering dengan KMeans')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.show()

"""(Opsional) Membangun Model Clustering [Advanced]

**Biarkan kosong jika tidak menerapkan kriteria advanced**
"""

# Membangun model menggunakan PCA.
# ___ =PCA(n_components=<x>)
# ___ = ____.fit_transform(___)
# Menyimpan data PCA sebagai Dataframe dengan nama PCA_<numbers>
# <data_final> = pd.DataFrame(___, columns=['PCA1', 'PCA2', <sesuaikan dengan jumlah n>])
# Pastikan kamu membangun model Kmeans baru dengan data yang sudah dimodifikasi melalui PCA.
# ___ = KMeans(n_clusters=<x>)
# ___.fit(<data_final>)

pca = PCA(n_components=2)
pca_components = pca.fit_transform(df[features])

PCA_2 = pd.DataFrame(pca_components, columns=['PCA1', 'PCA2'])

model_kmeans_pca = KMeans(n_clusters=3, random_state=42)
model_kmeans_pca.fit(PCA_2)

# Simpan model PCA sebagai perbandingan dengan menjalankan cell code ini joblib.dump(model,"PCA_model_clustering.h5")
# Pastikan yang disimpan model yang sudah melalui .fit berdasarkan dataset yang sudah dilakukan PCA
# joblib.dump(___, "PCA_model_clustering.h5")

joblib.dump(model_kmeans_pca, "PCA_model_clustering.h5")

"""# **5. Interpretasi Cluster**

## **a. Interpretasi Hasil Clustering**
1. **Contoh Interpretasi:**
- **Cluster 1: (Nasabah Bertransaksi dan Pendapatan Besar)**:
  - **Rata-rata (mean) Annual Income:** 0.953 (48,260)
  - **Rata-rata (mean) Spending Score:** 0.8 (56.48)
  - **Analisis:** Cluster ini mencakup pelanggan dengan pendapatan tahunan tinggi dan tingkat pengeluaran yang cukup tinggi. Pelanggan dalam cluster ini cenderung memiliki daya beli yang tinggi dan mereka lebih cenderung untuk membelanjakan sebagian besar pendapatan mereka. Sehingga rekomendasi pada kelompok nasabah ini adalah dengan menawarkan produk-produk investasi atau perbankan yang berkualitas tinggi.
"""

# Menampilkan analisis deskriptif minimal mean, min dan max untuk fitur numerik.
# Silakan menambahkan fungsi agregasi lainnya untuk experience lebih baik.
# pastikan output menghasilkan agregasi dan groupby bersamaan dengan mean, min, dan max.

numerical_features = ['TransactionAmount', 'AccountBalance', 'TransactionDuration', 'LoginAttempts', 'CustomerAge']

df['Cluster'] = model_kmeans.labels_

cluster_analysis = df.groupby('Cluster')[numerical_features].agg(['mean', 'min', 'max'])
cluster_analysis

"""## Menjelaskan karakteristik tiap cluster berdasarkan rentangnya.

# Interpretasi Cluster

## Cluster 0

**Rata-rata TransactionAmount:** 0.142  
**Rata-rata AccountBalance:** 0.333  
**Rata-rata TransactionDuration:** 0.126  
**Rata-rata LoginAttempts:** 0.023  
**Rata-rata CustomerAge:** 0.426  

**Analisis:**  
Pelanggan di cluster ini cenderung melakukan transaksi kecil dan memiliki saldo menengah. Mereka biasanya menyelesaikan transaksi dengan cepat dan jarang login. Yang menunjukkan sifat yang berhati-hati dan lebih pasif dalam aktivitas keuangan sehari-hari. Strategi pemasaran yang cocok adalah edukasi produk ringan atau promosi sederhana agar mereka lebih terlibat.

## Cluster 1

**Rata-rata TransactionAmount:** 0.144  
**Rata-rata AccountBalance:** 0.338  
**Rata-rata TransactionDuration:** 0.647  
**Rata-rata LoginAttempts:** 0.031  
**Rata-rata CustomerAge:** 0.422  

**Analisis:**  
Pelanggan di cluster ini memiliki durasi transaksi lebih lama dan aktivitas login sedikit lebih tinggi. Mereka tampak teliti dan ingin memastikan setiap transaksi dilakukan dengan benar. Strategi pemasaran sebaiknya menekankan informasi produk yang lengkap dan penawaran yang jelas agar mereka merasa yakin dan nyaman.

## Cluster 2

**Rata-rata TransactionAmount:** 0.157  
**Rata-rata AccountBalance:** 0.340  
**Rata-rata TransactionDuration:** 0.353  
**Rata-rata LoginAttempts:** 0.037  
**Rata-rata CustomerAge:** 0.440  

**Analisis:**  
Cluster ini berisi pelanggan yang lebih aktif, dengan transaksi sedikit lebih besar dan durasi sedang. Mereka lebih sering login dibanding cluster lain, menunjukkan minat dan keterlibatan yang lebih tinggi. Strategi pemasaran dapat fokus pada promosi menarik dan penawaran khusus untuk meningkatkan loyalitas, sambil tetap memberikan informasi produk yang jelas agar pelanggan tetap nyaman dan percaya.

# **6. Mengeksport Data**

1. Simpan nama kolom hasil clustering dengan nama `Target`.
2. Simpan hasilnya ke dalam file CSV menggunakan function `to_csv()`.
"""

# Pastikan nama kolom clustering sudah diubah menjadi Target
df['Target'] = model_kmeans.labels_

# Simpan Data
# ___.to_csv('data_clustering.csv', index=False)
df.to_csv('data_clustering.csv', index=False)

"""(Opsional) Interpretasi Hasil Clustering [Skilled]

**Biarkan kosong jika tidak menerapkan kriteria skilled**
"""

# inverse dataset ke rentang normal untuk numerikal
# df[numerical_cols] = <nama_scaler>.inverse_transform(df[numerical_cols])
# tampilkan dataset yang sudah di-inverse
# ___.head()

numerical_cols = ['TransactionAmount', 'AccountBalance', 'TransactionDuration', 'LoginAttempts', 'CustomerAge']
df[numerical_cols] = scaler.inverse_transform(df[numerical_cols])
df.head()

# inverse dataset yang sudah diencode ke kategori aslinya.
# Lengkapi kode berikut jika ingin menerapkan kriteria ini (silakan hapus simbol pagar pada kode yang akan digunakan.)
# for ___ in categorical_cols:
#     ___ = encoders[col]
#     df[col] = ___.inverse_transform(df_inverse[col].astype(int))
# tampilkan dataset yang sudah di-inverse
# ___.head()

# The categorical columns appear to be already in their original string format.
# This step is causing an error by attempting to inverse transform them again.
# Removing the code in this cell.

# Lakukan analisis deskriptif minimal mean, min dan max untuk fitur numerik dan mode untuk kategorikal seperti pada basic tetapi menggunakan data yang sudah diinverse.
# pastikan output menghasilkan agregasi dan groupby bersamaan dengan mean, min, dan max kembali setelah melakukan inverse.

numerical_cols = ['TransactionAmount', 'AccountBalance', 'TransactionDuration', 'LoginAttempts', 'CustomerAge']
categorical_cols = ['TransactionType', 'Location', 'Channel', 'CustomerOccupation']

numerical_agg = df.groupby('Target')[numerical_cols].agg(['mean', 'min', 'max'])

categorical_agg = df.groupby('Target')[categorical_cols].agg(lambda x: x.mode().iloc[0])

descriptive_summary = pd.concat([numerical_agg, categorical_agg], axis=1)
descriptive_summary

"""## Menjelaskan karakteristik tiap cluster berdasarkan rentangnya setelah inverse

### Cluster 0

**Rata-rata TransactionAmount:** 272.73  
**Minimum TransactionAmount:** 0.84  
**Maksimum TransactionAmount:** 899.24  

**Rata-rata AccountBalance:** 5,048.21  
**Minimum AccountBalance:** 101.25  
**Maksimum AccountBalance:** 14,977.99  

**Rata-rata TransactionDuration:** 46.48 detik  
**Minimum TransactionDuration:** 10 detik  
**Maksimum TransactionDuration:** 79 detik  

**Rata-rata LoginAttempts:** 1.09  
**Minimum LoginAttempts:** 1  
**Maksimum LoginAttempts:** 5  

**Rata-rata CustomerAge:** 44.43 tahun  
**Minimum CustomerAge:** 18  
**Maksimum CustomerAge:** 80  

**Modus TransactionType:** Debit  
**Modus Location:** Fort Worth  
**Modus Channel:** Branch  
**Modus CustomerOccupation:** Engineer  

**Analisis:**  
Pelanggan di cluster ini memiliki transaksi relatif sedang, saldo menengah, durasi transaksi singkat, dan login jarang. Mereka cenderung berhati-hati namun stabil dalam aktivitas finansial. Strategi pemasaran yang cocok adalah edukasi produk ringan, promosi sederhana, atau penawaran produk yang mendukung kestabilan finansial.

### Cluster 1

**Rata-rata TransactionAmount:** 276.94  
**Minimum TransactionAmount:** 0.26  
**Maksimum TransactionAmount:** 899.24  

**Rata-rata AccountBalance:** 5,124.40  
**Minimum AccountBalance:** 106.86  
**Maksimum AccountBalance:** 14,928.35  

**Rata-rata TransactionDuration:** 197.77 detik  
**Minimum TransactionDuration:** 144 detik  
**Maksimum TransactionDuration:** 300 detik  

**Rata-rata LoginAttempts:** 1.13  
**Minimum LoginAttempts:** 1  
**Maksimum LoginAttempts:** 5  

**Rata-rata CustomerAge:** 44.18 tahun  
**Minimum CustomerAge:** 18  
**Maksimum CustomerAge:** 80  

**Modus TransactionType:** Debit  
**Modus Location:** Atlanta  
**Modus Channel:** ATM  
**Modus CustomerOccupation:** Student  

**Analisis:**  
Pelanggan di cluster ini melakukan transaksi lebih lama dibanding cluster lain, dengan login sedikit lebih sering. Mereka tampak teliti saat bertransaksi. Strategi pemasaran yang cocok adalah rekomendasi produk yang detail, promosi edukatif, dan penawaran menarik untuk mendorong keterlibatan.

### Cluster 2

**Rata-rata TransactionAmount:** 301.50  
**Minimum TransactionAmount:** 0.32  
**Maksimum TransactionAmount:** 899.24  

**Rata-rata AccountBalance:** 5,165.95  
**Minimum AccountBalance:** 105.01  
**Maksimum AccountBalance:** 14,942.78  

**Rata-rata TransactionDuration:** 112.38 detik  
**Minimum TransactionDuration:** 80 detik  
**Maksimum TransactionDuration:** 143 detik  

**Rata-rata LoginAttempts:** 1.15  
**Minimum LoginAttempts:** 1  
**Maksimum LoginAttempts:** 5  

**Rata-rata CustomerAge:** 45.28 tahun  
**Minimum CustomerAge:** 18  
**Maksimum CustomerAge:** 80  

**Modus TransactionType:** Debit  
**Modus Location:** Kansas City  
**Modus Channel:** ATM  
**Modus CustomerOccupation:** Doctor  

**Analisis:**  
Cluster ini terdiri dari pelanggan yang memiliki transaksi lebih tinggi dan lebih aktif dibanding cluster lain, dengan durasi transaksi sedang. Mereka berhati-hati namun cukup sering melakukan login. Strategi pemasaran bisa berupa penawaran eksklusif, produk finansial premium, atau promosi untuk meningkatkan loyalitas.

(Opsional) Interpretasi Hasil Clustering [Advanced]

**Biarkan kosong jika tidak menerapkan kriteria advanced**
"""

# Mengintegrasikan kembali data yang telah di-inverse dengan hasil cluster.
df_inverse = df.copy()
df_inverse['Target'] = df['Target']

# Simpan Data
# ___.to_csv('data_clustering_inverse.csv', index=False)
df_inverse.to_csv('data_clustering_inverse.csv', index=False)

"""End of Code."""